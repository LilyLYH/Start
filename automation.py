#!/usr/bin/env python3


import csv
import sys
from datetime import datetime
from collections import Counter, defaultdict
import argparse

def parse_date(date_str):
    """è§£æå¤šç§æ—¥æœŸæ ¼å¼"""
    if not date_str or date_str.strip() == '':
        return None
    
    date_str = date_str.strip()
    
    # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼
    date_formats = [
        '%m/%d/%Y %I:%M:%S %p',  # 12/12/2025 3:30:19 PM
        '%Y-%m-%d %H:%M:%S',     # 2025-12-12 15:30:19
        '%m/%d/%Y',              # 12/12/2025
        '%Y-%m-%d'               # 2025-12-12
    ]
    
    for fmt in date_formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    print(f"è­¦å‘Šï¼šæ— æ³•è§£ææ—¥æœŸ: {date_str}")
    return None

def parse_csv_file(csv_file_path):
    """è§£æCSVæ–‡ä»¶å¹¶è¿”å›å·¥ä½œé¡¹æ•°æ®"""
    work_items = []
    
    try:
        with open(csv_file_path, 'r', encoding='utf-8-sig') as file:
            # ä½¿ç”¨DictReaderæŒ‰åˆ—åè®¿é—®æ•°æ®
            reader = csv.DictReader(file)
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['ID', 'Work Item Type', 'Title', 'State', 'Created Date']
            for col in required_columns:
                if col not in reader.fieldnames:
                    print(f"é”™è¯¯ï¼šCSVæ–‡ä»¶ä¸­ç¼ºå°‘å¿…éœ€çš„åˆ—ï¼š{col}")
                    print(f"æ‰¾åˆ°çš„åˆ—ï¼š{reader.fieldnames}")
                    return []
            
            print(f"æ‰¾åˆ°çš„åˆ—ï¼š{list(reader.fieldnames)}")
            
            # è¯»å–æ¯ä¸€è¡Œæ•°æ®
            for row_num, row in enumerate(reader, 1):
                try:
                    # è§£ææ—¥æœŸ
                    created_date = parse_date(row['Created Date'])
                    closed_date = parse_date(row.get('Closed Date', ''))
                    
                    # è§£ææŒ‡æ´¾ç»™ï¼ˆç§»é™¤é‚®ç®±éƒ¨åˆ†ï¼‰
                    assigned_to = row.get('Assigned To', '').split('<')[0].strip() if row.get('Assigned To') else 'Unassigned'
                    
                    # è§£æåŒºåŸŸè·¯å¾„
                    area_path = row.get('Area Path', '')
                    
                    # è·å–æœ€åä¸€éƒ¨åˆ†ä½œä¸ºå›¢é˜Ÿ/æ¨¡å—
                    if area_path:
                        area_parts = area_path.split('\\')
                        team = area_parts[-1] if area_parts else area_path
                    else:
                        team = 'Unknown'
                    
                    # è®¡ç®—è§£å†³æ—¶é—´ï¼ˆå¦‚æœå·²å…³é—­ï¼‰
                    resolution_time = None
                    if closed_date and created_date:
                        resolution_time = (closed_date - created_date).days
                    
                    # è§£æStory Points
                    story_points = 0
                    try:
                        if row.get('Story Points'):
                            story_points = float(row['Story Points'])
                    except (ValueError, TypeError):
                        pass
                    
                    # åˆ›å»ºå·¥ä½œé¡¹å¯¹è±¡
                    work_item = {
                        'id': row['ID'],
                        'type': row['Work Item Type'],
                        'title': row['Title'],
                        'assigned_to': assigned_to,
                        'state': row['State'],
                        'tags': row.get('Tags', '').split(';') if row.get('Tags') else [],
                        'created_date': created_date,
                        'priority': row.get('Priority', 'Not Set'),
                        'closed_date': closed_date,
                        'story_points': story_points,
                        'area_path': area_path,
                        'team': team,
                        'resolution_days': resolution_time
                    }
                    
                    work_items.append(work_item)
                    
                except KeyError as e:
                    print(f"è­¦å‘Šï¼šç¬¬{row_num}è¡Œç¼ºå°‘å­—æ®µï¼š{e}")
                except Exception as e:
                    print(f"è­¦å‘Šï¼šç¬¬{row_num}è¡Œè§£æå¤±è´¥ï¼š{e}")
                    print(f"è¡Œæ•°æ®ï¼š{row}")
                    
        print(f"æˆåŠŸè§£æ {len(work_items)} ä¸ªå·¥ä½œé¡¹")
        return work_items
        
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ–‡ä»¶ '{csv_file_path}' æœªæ‰¾åˆ°")
        sys.exit(1)
    except PermissionError:
        print(f"é”™è¯¯ï¼šæ²¡æœ‰æƒé™è¯»å–æ–‡ä»¶ '{csv_file_path}'")
        sys.exit(1)
    except Exception as e:
        print(f"è§£ææ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

def analyze_work_items(work_items):
    """åˆ†æå·¥ä½œé¡¹æ•°æ®"""
    if not work_items:
        return {}
    
    analysis = {
        'total_items': len(work_items),
        'type_distribution': Counter(),
        'state_distribution': Counter(),
        'priority_distribution': Counter(),
        'team_distribution': Counter(),
        'assignee_distribution': Counter(),
        'open_items': [],
        'closed_items': [],
        'resolution_times': [],
        'story_points_total': 0,
        'story_points_by_team': defaultdict(float),
        'story_points_by_assignee': defaultdict(float),
        'story_points_by_type': defaultdict(float),
        'largest_story_items': [],
        'oldest_open_item': None,
        'newest_item': None
    }
    
    for item in work_items:
        # åŸºæœ¬ç»Ÿè®¡
        analysis['type_distribution'][item['type']] += 1
        analysis['state_distribution'][item['state']] += 1
        analysis['priority_distribution'][item['priority']] += 1
        analysis['team_distribution'][item['team']] += 1
        analysis['assignee_distribution'][item['assigned_to']] += 1
        
        # Story Pointsç»Ÿè®¡
        story_points = item['story_points']
        analysis['story_points_total'] += story_points
        analysis['story_points_by_team'][item['team']] += story_points
        analysis['story_points_by_assignee'][item['assigned_to']] += story_points
        analysis['story_points_by_type'][item['type']] += story_points
        
        # æŒ‰çŠ¶æ€åˆ†ç±»
        if item['state'].lower() in ['new', 'active', 'open', 'in progress']:
            analysis['open_items'].append(item)
        elif item['state'].lower() in ['closed', 'resolved', 'done']:
            analysis['closed_items'].append(item)
            
            # æ”¶é›†è§£å†³æ—¶é—´æ•°æ®
            if item['resolution_days'] is not None:
                analysis['resolution_times'].append(item['resolution_days'])
        
        # è®°å½•æœ€å¤§çš„Story Pointsé¡¹
        if story_points > 0:
            analysis['largest_story_items'].append({
                'id': item['id'],
                'title': item['title'],
                'story_points': story_points,
                'type': item['type'],
                'state': item['state'],
                'assigned_to': item['assigned_to'],
                'team': item['team']
            })
        
        # æ—¥æœŸç›¸å…³åˆ†æ
        if item['created_date']:
            if analysis['newest_item'] is None or item['created_date'] > analysis['newest_item']['date']:
                analysis['newest_item'] = {
                    'id': item['id'],
                    'date': item['created_date'],
                    'title': item['title'][:50] + '...' if len(item['title']) > 50 else item['title'],
                    'type': item['type'],
                    'story_points': story_points
                }
            
            # å¦‚æœæ˜¯å¼€æ”¾çŠ¶æ€ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæœ€æ—§çš„
            if item['state'].lower() in ['new', 'active', 'open', 'in progress']:
                if analysis['oldest_open_item'] is None or item['created_date'] < analysis['oldest_open_item']['date']:
                    age_days = (datetime.now() - item['created_date']).days
                    analysis['oldest_open_item'] = {
                        'id': item['id'],
                        'date': item['created_date'],
                        'title': item['title'][:50] + '...' if len(item['title']) > 50 else item['title'],
                        'age_days': age_days,
                        'priority': item['priority'],
                        'story_points': story_points
                    }
    
    # è®¡ç®—è§£å†³æ—¶é—´ç»Ÿè®¡
    if analysis['resolution_times']:
        analysis['avg_resolution_time'] = sum(analysis['resolution_times']) / len(analysis['resolution_times'])
        analysis['max_resolution_time'] = max(analysis['resolution_times'])
        analysis['min_resolution_time'] = min(analysis['resolution_times'])
    
    # å¯¹æœ€å¤§çš„Story Pointsé¡¹è¿›è¡Œæ’åº
    analysis['largest_story_items'].sort(key=lambda x: x['story_points'], reverse=True)
    
    return analysis

def get_story_points_rankings(analysis, top_n=10):
    """ç”ŸæˆStory Pointsæ’å"""
    rankings = {
        'by_assignee': [],
        'by_team': [],
        'by_type': [],
        'largest_items': analysis.get('largest_story_items', [])[:top_n]
    }
    
    # æŒ‰æŒ‡æ´¾äººæ’å
    if analysis.get('story_points_by_assignee'):
        for assignee, points in sorted(analysis['story_points_by_assignee'].items(), 
                                      key=lambda x: x[1], reverse=True)[:top_n]:
            item_count = analysis['assignee_distribution'][assignee]
            avg_points = points / item_count if item_count > 0 else 0
            rankings['by_assignee'].append({
                'name': assignee,
                'total_points': points,
                'item_count': item_count,
                'avg_points': avg_points
            })
    
    # æŒ‰å›¢é˜Ÿæ’å
    if analysis.get('story_points_by_team'):
        for team, points in sorted(analysis['story_points_by_team'].items(), 
                                  key=lambda x: x[1], reverse=True)[:top_n]:
            item_count = analysis['team_distribution'][team]
            avg_points = points / item_count if item_count > 0 else 0
            rankings['by_team'].append({
                'name': team,
                'total_points': points,
                'item_count': item_count,
                'avg_points': avg_points
            })
    
    # æŒ‰ç±»å‹æ’å
    if analysis.get('story_points_by_type'):
        for item_type, points in sorted(analysis['story_points_by_type'].items(), 
                                       key=lambda x: x[1], reverse=True):
            item_count = analysis['type_distribution'][item_type]
            avg_points = points / item_count if item_count > 0 else 0
            rankings['by_type'].append({
                'name': item_type,
                'total_points': points,
                'item_count': item_count,
                'avg_points': avg_points
            })
    
    return rankings

def generate_report(analysis):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    if not analysis or analysis['total_items'] == 0:
        return "æ²¡æœ‰å¯åˆ†æçš„æ•°æ®"
    
    # è·å–Story Pointsæ’å
    rankings = get_story_points_rankings(analysis)
    
    report_lines = []
    report_lines.append("=" * 70)
    report_lines.append("             Azure DevOps å·¥ä½œé¡¹åˆ†ææŠ¥å‘Š")
    report_lines.append("=" * 70)
    report_lines.append(f"æ€»å·¥ä½œé¡¹æ•°: {analysis['total_items']}")
    report_lines.append(f"å¼€æ”¾é¡¹: {len(analysis['open_items'])} | å…³é—­é¡¹: {len(analysis['closed_items'])}")
    report_lines.append(f"æ€»Story Points: {analysis['story_points_total']:.1f}")
    
    # è®¡ç®—å¹³å‡Story Points
    avg_story_points = analysis['story_points_total'] / analysis['total_items'] if analysis['total_items'] > 0 else 0
    report_lines.append(f"å¹³å‡Story Points: {avg_story_points:.2f}")
    report_lines.append("")
    
    # Story Pointsæ’åéƒ¨åˆ†
    report_lines.append("ğŸ“Š STORY POINTS æ’ååˆ†æ")
    report_lines.append("=" * 50)
    
    # æŒ‰æŒ‡æ´¾äººæ’å
    if rankings['by_assignee']:
        report_lines.append("\næŒ‰æŒ‡æ´¾äººStory Pointsæ’å (å‰10å):")
        report_lines.append("-" * 60)
        report_lines.append(f"{'æ’å':<4} {'æŒ‡æ´¾äºº':<20} {'æ€»ç‚¹æ•°':<10} {'å·¥ä½œé¡¹æ•°':<10} {'å¹³å‡ç‚¹æ•°':<10}")
        report_lines.append("-" * 60)
        
        for i, assignee_data in enumerate(rankings['by_assignee'][:10], 1):
            report_lines.append(
                f"{i:<4} {assignee_data['name']:<20} "
                f"{assignee_data['total_points']:<10.1f} "
                f"{assignee_data['item_count']:<10} "
                f"{assignee_data['avg_points']:<10.2f}"
            )
    
    # æŒ‰å›¢é˜Ÿæ’å
    if rankings['by_team']:
        report_lines.append("\næŒ‰å›¢é˜ŸStory Pointsæ’å (å‰10å):")
        report_lines.append("-" * 60)
        report_lines.append(f"{'æ’å':<4} {'å›¢é˜Ÿ':<25} {'æ€»ç‚¹æ•°':<10} {'å·¥ä½œé¡¹æ•°':<10} {'å¹³å‡ç‚¹æ•°':<10}")
        report_lines.append("-" * 60)
        
        for i, team_data in enumerate(rankings['by_team'][:10], 1):
            report_lines.append(
                f"{i:<4} {team_data['name']:<25} "
                f"{team_data['total_points']:<10.1f} "
                f"{team_data['item_count']:<10} "
                f"{team_data['avg_points']:<10.2f}"
            )
    
    # æŒ‰ç±»å‹æ’å
    if rankings['by_type']:
        report_lines.append("\næŒ‰ç±»å‹Story Pointsæ’å:")
        report_lines.append("-" * 45)
        report_lines.append(f"{'ç±»å‹':<15} {'æ€»ç‚¹æ•°':<10} {'å·¥ä½œé¡¹æ•°':<10} {'å¹³å‡ç‚¹æ•°':<10}")
        report_lines.append("-" * 45)
        
        for type_data in rankings['by_type']:
            report_lines.append(
                f"{type_data['name']:<15} "
                f"{type_data['total_points']:<10.1f} "
                f"{type_data['item_count']:<10} "
                f"{type_data['avg_points']:<10.2f}"
            )
    
    # æœ€å¤§çš„Story Pointsé¡¹
    if rankings['largest_items']:
        report_lines.append("\nğŸ” æœ€å¤§çš„Story Pointså·¥ä½œé¡¹ (å‰10å):")
        report_lines.append("-" * 70)
        report_lines.append(f"{'æ’å':<4} {'ID':<10} {'ç‚¹æ•°':<8} {'ç±»å‹':<10} {'çŠ¶æ€':<12} {'æŒ‡æ´¾äºº':<15} {'æ ‡é¢˜'}")
        report_lines.append("-" * 70)
        
        for i, item in enumerate(rankings['largest_items'][:10], 1):
            title_display = item['title'][:30] + '...' if len(item['title']) > 30 else item['title']
            report_lines.append(
                f"{i:<4} {item['id']:<10} "
                f"{item['story_points']:<8.1f} "
                f"{item['type']:<10} "
                f"{item['state']:<12} "
                f"{item['assigned_to'][:14]:<15} "
                f"{title_display}"
            )
    
    report_lines.append("\n" + "=" * 70)
    report_lines.append("ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
    report_lines.append("=" * 50)
    
    # å·¥ä½œé¡¹ç±»å‹åˆ†å¸ƒ
    report_lines.append("\nå·¥ä½œé¡¹ç±»å‹åˆ†å¸ƒ:")
    report_lines.append("-" * 35)
    for item_type, count in analysis['type_distribution'].most_common():
        percentage = (count / analysis['total_items']) * 100
        points_percentage = (analysis['story_points_by_type'][item_type] / analysis['story_points_total'] * 100) if analysis['story_points_total'] > 0 else 0
        report_lines.append(f"  {item_type:<15} {count:>3} ({percentage:>5.1f}%) | ç‚¹æ•°: {analysis['story_points_by_type'][item_type]:>5.1f} ({points_percentage:>5.1f}%)")
    report_lines.append("")
    
    # çŠ¶æ€åˆ†å¸ƒ
    report_lines.append("çŠ¶æ€åˆ†å¸ƒ:")
    report_lines.append("-" * 35)
    for state, count in analysis['state_distribution'].most_common():
        percentage = (count / analysis['total_items']) * 100
        report_lines.append(f"  {state:<15} {count:>3} ({percentage:>5.1f}%)")
    report_lines.append("")
    
    # ä¼˜å…ˆçº§åˆ†å¸ƒ
    report_lines.append("ä¼˜å…ˆçº§åˆ†å¸ƒ:")
    report_lines.append("-" * 35)
    for priority, count in sorted(analysis['priority_distribution'].items(), 
                                  key=lambda x: int(x[0]) if x[0].isdigit() else 999):
        percentage = (count / analysis['total_items']) * 100
        report_lines.append(f"  Priority {priority:<5} {count:>3} ({percentage:>5.1f}%)")
    report_lines.append("")
    
    # è§£å†³æ—¶é—´ç»Ÿè®¡
    if 'avg_resolution_time' in analysis:
        report_lines.append("è§£å†³æ—¶é—´ç»Ÿè®¡ (å·²å…³é—­é¡¹ç›®):")
        report_lines.append("-" * 35)
        report_lines.append(f"  å¹³å‡è§£å†³æ—¶é—´: {analysis['avg_resolution_time']:.1f} å¤©")
        report_lines.append(f"  æœ€é•¿è§£å†³æ—¶é—´: {analysis['max_resolution_time']} å¤©")
        report_lines.append(f"  æœ€çŸ­è§£å†³æ—¶é—´: {analysis['min_resolution_time']} å¤©")
        report_lines.append(f"  æ€»å…³é—­é¡¹æ•°: {len(analysis['closed_items'])}")
        report_lines.append("")
    
    # æœ€æ—§çš„å¼€æ”¾é¡¹
    if analysis['oldest_open_item']:
        oldest = analysis['oldest_open_item']
        report_lines.append("æœ€æ—§çš„å¼€æ”¾å·¥ä½œé¡¹:")
        report_lines.append("-" * 35)
        report_lines.append(f"  ID: {oldest['id']}")
        report_lines.append(f"  åˆ›å»ºæ—¶é—´: {oldest['date'].strftime('%Y-%m-%d')}")
        report_lines.append(f"  å·²å¼€æ”¾å¤©æ•°: {oldest['age_days']} å¤©")
        report_lines.append(f"  ä¼˜å…ˆçº§: {oldest['priority']}")
        report_lines.append(f"  Story Points: {oldest['story_points']}")
        report_lines.append(f"  æ ‡é¢˜: {oldest['title']}")
        report_lines.append("")
    
    # æœ€æ–°é¡¹
    if analysis['newest_item']:
        newest = analysis['newest_item']
        report_lines.append("æœ€æ–°åˆ›å»ºçš„å·¥ä½œé¡¹:")
        report_lines.append("-" * 35)
        report_lines.append(f"  ID: {newest['id']}")
        report_lines.append(f"  ç±»å‹: {newest['type']}")
        report_lines.append(f"  åˆ›å»ºæ—¶é—´: {newest['date'].strftime('%Y-%m-%d %H:%M')}")
        report_lines.append(f"  Story Points: {newest['story_points']}")
        report_lines.append(f"  æ ‡é¢˜: {newest['title']}")
    
    report_lines.append("=" * 70)
    
    return "\n".join(report_lines)

def generate_sample_csv():
    """ç”Ÿæˆç¬¦åˆå®é™…æ ¼å¼çš„ç¤ºä¾‹CSV"""
    sample_csv = """ID,Work Item Type,Title,Assigned To,State,Tags,Created Date,Priority,Closed Date,Story Points,Area Path
"79906","Bug","Ads tool tip not showing correctly","Jason Lin <jalin@lifetime.com>","Closed",,"12/12/2025 3:30:19 PM","2","12/15/2025 12:53:54 PM","1","Lifetime Applications\External\Web\Valas"
"79907","Task","Update documentation for API v2","Sarah Chen <schen@lifetime.com>","In Progress","documentation;api","12/10/2025 10:15:00 AM","3",,"3","Lifetime Applications\Internal\Web\API"
"79908","Bug","Login page crashes on mobile","Mike Johnson <mjohnson@lifetime.com>","New","urgent;mobile","12/16/2025 9:45:00 AM","1",,"2","Lifetime Applications\External\Web\Valas"
"79909","User Story","Implement user profile page","Alex Wang <awang@lifetime.com>","Closed","ui;profile","12/01/2025 2:00:00 PM","2","12/10/2025 4:30:00 PM","8","Lifetime Applications\External\Mobile"
"79910","Bug","Database connection timeout","Jason Lin <jalin@lifetime.com>","Resolved","database","12/05/2025 11:20:00 AM","1","12/07/2025 3:15:00 PM","3","Lifetime Applications\Internal\Services"
"79911","Task","Code review for PR #456","Sarah Chen <schen@lifetime.com>","New","code-review","12/15/2025 4:30:00 PM","3",,"2","Lifetime Applications\Internal\Web\API"
"79912","Bug","CSS alignment issue in Firefox","Mike Johnson <mjohnson@lifetime.com>","Closed","css;firefox","12/08/2025 2:45:00 PM","2","12/09/2025 11:30:00 AM","1","Lifetime Applications\External\Web\Valas"
"79913","User Story","Add search functionality","Alex Wang <awang@lifetime.com>","In Progress","search;feature","12/03/2025 9:00:00 AM","2",,"13","Lifetime Applications\External\Mobile"
"79914","Task","Setup CI/CD pipeline","David Kim <dkim@lifetime.com>","Done","devops;ci-cd","11/25/2025 1:15:00 PM","3","12/05/2025 5:00:00 PM","5","Lifetime Applications\Internal\DevOps"
"79915","Bug","Memory leak in analytics module","Jason Lin <jalin@lifetime.com>","Active","memory;analytics","12/14/2025 3:00:00 PM","1",,"2","Lifetime Applications\External\Web\Valas"
"79916","User Story","Redesign dashboard UI","Emma Wilson <ewilson@lifetime.com>","Closed","ui;dashboard","12/02/2025 10:00:00 AM","2","12/12/2025 3:00:00 PM","5","Lifetime Applications\External\Web\Valas"
"79917","Task","Update dependencies","Tom Brown <tbrown@lifetime.com>","New","maintenance","12/17/2025 11:00:00 AM","3",,"1","Lifetime Applications\Internal\Services"
"79918","Bug","Performance issue on checkout","Jason Lin <jalin@lifetime.com>","Active","performance","12/13/2025 2:30:00 PM","1",,"3","Lifetime Applications\External\Web\Valas"
"79919","User Story","Implement payment gateway","Sarah Chen <schen@lifetime.com>","In Progress","payment;feature","12/05/2025 9:30:00 AM","2",,"8","Lifetime Applications\External\Mobile"
"79920","Task","Write unit tests for auth module","Mike Johnson <mjohnson@lifetime.com>","New","testing","12/16/2025 3:00:00 PM","3",,"3","Lifetime Applications\Internal\Web\API"""
    
    return sample_csv

def save_sample_csv(filename="azure_devops_sample.csv"):
    """ä¿å­˜ç¤ºä¾‹CSVæ–‡ä»¶"""
    sample_data = generate_sample_csv()
    
    try:
        with open(filename, 'w', encoding='utf-8') as file:
            file.write(sample_data)
        print(f"ç¤ºä¾‹CSVæ–‡ä»¶å·²ä¿å­˜ä¸º: {filename}")
        print(f"ä½¿ç”¨å‘½ä»¤æµ‹è¯•: python azure_analyzer.py {filename}")
        return filename
    except Exception as e:
        print(f"ä¿å­˜ç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {e}")
        return None

def export_story_points_analysis(analysis, filename="story_points_analysis.csv"):
    """å¯¼å‡ºStory Pointsåˆ†ææŠ¥å‘Š"""
    if not analysis or analysis['total_items'] == 0:
        print("æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
        return False
    
    try:
        rankings = get_story_points_rankings(analysis)
        
        with open(filename, 'w', encoding='utf-8', newline='') as file:
            writer = csv.writer(file)
            
            # å†™å…¥æ ‡é¢˜
            writer.writerow(["Story Points è¯¦ç»†åˆ†ææŠ¥å‘Š"])
            writer.writerow([])
            
            # æ±‡æ€»ä¿¡æ¯
            writer.writerow(["æ±‡æ€»ä¿¡æ¯"])
            writer.writerow(["æ€»å·¥ä½œé¡¹æ•°", analysis['total_items']])
            writer.writerow(["æ€»Story Points", f"{analysis['story_points_total']:.2f}"])
            writer.writerow(["å¹³å‡Story Points", f"{analysis['story_points_total']/analysis['total_items']:.2f}"])
            writer.writerow([])
            
            # æŒ‰æŒ‡æ´¾äººæ’å
            writer.writerow(["æŒ‰æŒ‡æ´¾äººStory Pointsæ’å"])
            writer.writerow(["æ’å", "æŒ‡æ´¾äºº", "æ€»ç‚¹æ•°", "å·¥ä½œé¡¹æ•°", "å¹³å‡ç‚¹æ•°"])
            for i, assignee_data in enumerate(rankings['by_assignee'], 1):
                writer.writerow([
                    i,
                    assignee_data['name'],
                    f"{assignee_data['total_points']:.2f}",
                    assignee_data['item_count'],
                    f"{assignee_data['avg_points']:.2f}"
                ])
            writer.writerow([])
            
            # æŒ‰å›¢é˜Ÿæ’å
            writer.writerow(["æŒ‰å›¢é˜ŸStory Pointsæ’å"])
            writer.writerow(["æ’å", "å›¢é˜Ÿ", "æ€»ç‚¹æ•°", "å·¥ä½œé¡¹æ•°", "å¹³å‡ç‚¹æ•°"])
            for i, team_data in enumerate(rankings['by_team'], 1):
                writer.writerow([
                    i,
                    team_data['name'],
                    f"{team_data['total_points']:.2f}",
                    team_data['item_count'],
                    f"{team_data['avg_points']:.2f}"
                ])
            writer.writerow([])
            
            # æœ€å¤§çš„Story Pointsé¡¹
            writer.writerow(["æœ€å¤§çš„Story Pointså·¥ä½œé¡¹"])
            writer.writerow(["æ’å", "ID", "ç‚¹æ•°", "ç±»å‹", "çŠ¶æ€", "æŒ‡æ´¾äºº", "å›¢é˜Ÿ", "æ ‡é¢˜"])
            for i, item in enumerate(rankings['largest_items'][:20], 1):
                writer.writerow([
                    i,
                    item['id'],
                    f"{item['story_points']:.1f}",
                    item['type'],
                    item['state'],
                    item['assigned_to'],
                    item['team'],
                    item['title']
                ])
        
        print(f"Story Pointsåˆ†ææŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}")
        return True
        
    except Exception as e:
        print(f"å¯¼å‡ºStory Pointsåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Azure DevOpså·¥ä½œé¡¹åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s data.csv                    # åˆ†æCSVæ–‡ä»¶
  %(prog)s --sample                    # ç”Ÿæˆç¤ºä¾‹æ–‡ä»¶
  %(prog)s data.csv --story-points-report  # å¯¼å‡ºStory Pointsåˆ†ææŠ¥å‘Š
        """
    )
    
    parser.add_argument('csv_file', nargs='?', help='CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--sample', action='store_true', help='ç”Ÿæˆç¤ºä¾‹CSVæ–‡ä»¶')
    parser.add_argument('--story-points-report', metavar='FILE', 
                       help='å¯¼å‡ºStory Pointsåˆ†ææŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--top-n', type=int, default=10, 
                       help='æ˜¾ç¤ºå‰Nåæ’å (é»˜è®¤: 10)')
    
    args = parser.parse_args()
    
    # ç”Ÿæˆç¤ºä¾‹æ–‡ä»¶
    if args.sample:
        filename = save_sample_csv()
        if filename:
            print("\nç¤ºä¾‹æ–‡ä»¶å†…å®¹é¢„è§ˆ:")
            print("-" * 40)
            lines = generate_sample_csv().split('\n')[:5]
            for line in lines:
                print(line)
        return
    
    # æ£€æŸ¥æ–‡ä»¶å‚æ•°
    if not args.csv_file:
        print("è¯·æä¾›CSVæ–‡ä»¶è·¯å¾„")
        parser.print_help()
        return
    
    print(f"å¼€å§‹åˆ†ææ–‡ä»¶: {args.csv_file}")
    print("-" * 50)
    
    # è§£æCSVæ–‡ä»¶
    work_items = parse_csv_file(args.csv_file)
    
    if not work_items:
        print("æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆçš„å·¥ä½œé¡¹æ•°æ®")
        return
    
    # åˆ†ææ•°æ®
    print("æ­£åœ¨åˆ†ææ•°æ®...")
    analysis = analyze_work_items(work_items)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_report(analysis)
    
    # è¾“å‡ºæŠ¥å‘Š
    print("\n" + report)
    
    # å¯¼å‡ºStory Pointsåˆ†ææŠ¥å‘Š
    if args.story_points_report:
        export_story_points_analysis(analysis, args.story_points_report)
    
    # æä¾›åŸºäºStory Pointsçš„å»ºè®®
    print("\nğŸ“‹ åŸºäºStory Pointsçš„åˆ†æå»ºè®®:")
    print("-" * 50)
    
    total_points = analysis['story_points_total']
    open_items = analysis['open_items']
    
    if open_items:
        open_points = sum(item['story_points'] for item in open_items)
        open_percentage = (open_points / total_points * 100) if total_points > 0 else 0
        
        print(f"ğŸ“Š å½“å‰å¼€æ”¾é¡¹Story Points: {open_points:.1f} ({open_percentage:.1f}% of total)")
        
        # æŒ‰æŒ‡æ´¾äººåˆ†æå¼€æ”¾é¡¹ç‚¹æ•°
        print("\næŒ‰æŒ‡æ´¾äººå¼€æ”¾é¡¹Story Pointsåˆ†å¸ƒ:")
        assignee_open_points = defaultdict(float)
        for item in open_items:
            assignee_open_points[item['assigned_to']] += item['story_points']
        
        for assignee, points in sorted(assignee_open_points.items(), key=lambda x: x[1], reverse=True):
            print(f"  {assignee}: {points:.1f} points")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¿‡è½½çš„æŒ‡æ´¾äºº
        avg_open_points = open_points / len(assignee_open_points) if assignee_open_points else 0
        for assignee, points in assignee_open_points.items():
            if points > avg_open_points * 2:
                print(f"âš ï¸  {assignee} çš„å¼€æ”¾é¡¹ç‚¹æ•° ({points:.1f}) æ˜æ˜¾é«˜äºå¹³å‡ ({avg_open_points:.1f})")
    
    # æ£€æŸ¥æœ€å¤§çš„å¼€æ”¾é¡¹
    largest_open_items = sorted([item for item in open_items if item['story_points'] > 0], 
                               key=lambda x: x['story_points'], reverse=True)[:3]
    
    if largest_open_items:
        print("\nğŸ” æœ€å¤§çš„å¼€æ”¾é¡¹ (æŒ‰Story Points):")
        for item in largest_open_items:
            print(f"  {item['id']}: {item['title'][:40]}... ({item['story_points']} points)")

if __name__ == "__main__":
    main()